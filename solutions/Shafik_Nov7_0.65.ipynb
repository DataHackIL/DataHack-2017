{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shafik\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import optimizers\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os, tempfile\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "from scipy import linalg\n",
    "from sklearn import svm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 120\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "random.seed(12345)\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "name = ''\n",
    "out_name = path + name + 'submission_py.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          doprint=True,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    if doprint:\n",
    "        print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    if doprint:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv('train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28746, 362)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>posX_0</th>\n",
       "      <th>posY_0</th>\n",
       "      <th>posZ_0</th>\n",
       "      <th>velX_0</th>\n",
       "      <th>velY_0</th>\n",
       "      <th>velZ_0</th>\n",
       "      <th>diffposX_0</th>\n",
       "      <th>diffposX_0.1</th>\n",
       "      <th>diffposX_0.2</th>\n",
       "      <th>diffposX_0.3</th>\n",
       "      <th>diffposX_0.4</th>\n",
       "      <th>diffposX_0.5</th>\n",
       "      <th>posX_1</th>\n",
       "      <th>posY_1</th>\n",
       "      <th>posZ_1</th>\n",
       "      <th>velX_1</th>\n",
       "      <th>velY_1</th>\n",
       "      <th>velZ_1</th>\n",
       "      <th>diffposX_1</th>\n",
       "      <th>diffposX_1.1</th>\n",
       "      <th>diffposX_1.2</th>\n",
       "      <th>diffposX_1.3</th>\n",
       "      <th>diffposX_1.4</th>\n",
       "      <th>diffposX_1.5</th>\n",
       "      <th>posX_2</th>\n",
       "      <th>posY_2</th>\n",
       "      <th>posZ_2</th>\n",
       "      <th>velX_2</th>\n",
       "      <th>velY_2</th>\n",
       "      <th>velZ_2</th>\n",
       "      <th>diffposX_2</th>\n",
       "      <th>diffposX_2.1</th>\n",
       "      <th>diffposX_2.2</th>\n",
       "      <th>diffposX_2.3</th>\n",
       "      <th>diffposX_2.4</th>\n",
       "      <th>diffposX_2.5</th>\n",
       "      <th>posX_3</th>\n",
       "      <th>posY_3</th>\n",
       "      <th>posZ_3</th>\n",
       "      <th>velX_3</th>\n",
       "      <th>velY_3</th>\n",
       "      <th>velZ_3</th>\n",
       "      <th>diffposX_3</th>\n",
       "      <th>diffposX_3.1</th>\n",
       "      <th>diffposX_3.2</th>\n",
       "      <th>diffposX_3.3</th>\n",
       "      <th>diffposX_3.4</th>\n",
       "      <th>diffposX_3.5</th>\n",
       "      <th>posX_4</th>\n",
       "      <th>...</th>\n",
       "      <th>diffposX_25.5</th>\n",
       "      <th>posX_26</th>\n",
       "      <th>posY_26</th>\n",
       "      <th>posZ_26</th>\n",
       "      <th>velX_26</th>\n",
       "      <th>velY_26</th>\n",
       "      <th>velZ_26</th>\n",
       "      <th>diffposX_26</th>\n",
       "      <th>diffposX_26.1</th>\n",
       "      <th>diffposX_26.2</th>\n",
       "      <th>diffposX_26.3</th>\n",
       "      <th>diffposX_26.4</th>\n",
       "      <th>diffposX_26.5</th>\n",
       "      <th>posX_27</th>\n",
       "      <th>posY_27</th>\n",
       "      <th>posZ_27</th>\n",
       "      <th>velX_27</th>\n",
       "      <th>velY_27</th>\n",
       "      <th>velZ_27</th>\n",
       "      <th>diffposX_27</th>\n",
       "      <th>diffposX_27.1</th>\n",
       "      <th>diffposX_27.2</th>\n",
       "      <th>diffposX_27.3</th>\n",
       "      <th>diffposX_27.4</th>\n",
       "      <th>diffposX_27.5</th>\n",
       "      <th>posX_28</th>\n",
       "      <th>posY_28</th>\n",
       "      <th>posZ_28</th>\n",
       "      <th>velX_28</th>\n",
       "      <th>velY_28</th>\n",
       "      <th>velZ_28</th>\n",
       "      <th>diffposX_28</th>\n",
       "      <th>diffposX_28.1</th>\n",
       "      <th>diffposX_28.2</th>\n",
       "      <th>diffposX_28.3</th>\n",
       "      <th>diffposX_28.4</th>\n",
       "      <th>diffposX_28.5</th>\n",
       "      <th>posX_29</th>\n",
       "      <th>posY_29</th>\n",
       "      <th>posZ_29</th>\n",
       "      <th>velX_29</th>\n",
       "      <th>velY_29</th>\n",
       "      <th>velZ_29</th>\n",
       "      <th>diffposX_29</th>\n",
       "      <th>diffposX_29.1</th>\n",
       "      <th>diffposX_29.2</th>\n",
       "      <th>diffposX_29.3</th>\n",
       "      <th>diffposX_29.4</th>\n",
       "      <th>diffposX_29.5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476.575674</td>\n",
       "      <td>486.926974</td>\n",
       "      <td>3.057090</td>\n",
       "      <td>305.119216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>2.546763</td>\n",
       "      <td>2.536945e+04</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>241.974495</td>\n",
       "      <td>-3.247714</td>\n",
       "      <td>629.299199</td>\n",
       "      <td>483.225599</td>\n",
       "      <td>-0.534244</td>\n",
       "      <td>305.483552</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>-11.378862</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>2.502213</td>\n",
       "      <td>818127.34580</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>478.641960</td>\n",
       "      <td>2.505416</td>\n",
       "      <td>775.303988</td>\n",
       "      <td>479.884574</td>\n",
       "      <td>2.569264</td>\n",
       "      <td>295.705799</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.379544</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>2.633625</td>\n",
       "      <td>34886.387910</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>722.250011</td>\n",
       "      <td>1.029778</td>\n",
       "      <td>918.981911</td>\n",
       "      <td>476.162385</td>\n",
       "      <td>-0.844225</td>\n",
       "      <td>284.568090</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>1.444865</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>2.799869</td>\n",
       "      <td>318121.9958</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>958.719915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8073.292719</td>\n",
       "      <td>561.240579</td>\n",
       "      <td>0.939582</td>\n",
       "      <td>16.840572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.466693</td>\n",
       "      <td>1110.668463</td>\n",
       "      <td>3.568034e+05</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>284.446308</td>\n",
       "      <td>1.729876</td>\n",
       "      <td>8071.527369</td>\n",
       "      <td>555.568670</td>\n",
       "      <td>0.692598</td>\n",
       "      <td>3.101450</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>3.606218</td>\n",
       "      <td>839.124113</td>\n",
       "      <td>32088.245410</td>\n",
       "      <td>643446.46760</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>554.676870</td>\n",
       "      <td>-4.008367</td>\n",
       "      <td>8074.335689</td>\n",
       "      <td>555.637391</td>\n",
       "      <td>-2.662952</td>\n",
       "      <td>5.754135</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>-0.565250</td>\n",
       "      <td>243.863485</td>\n",
       "      <td>9324.443030</td>\n",
       "      <td>43536.770180</td>\n",
       "      <td>0.214174</td>\n",
       "      <td>834.907832</td>\n",
       "      <td>3.528096</td>\n",
       "      <td>8076.754846</td>\n",
       "      <td>550.590398</td>\n",
       "      <td>0.646220</td>\n",
       "      <td>-1.185523</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>8.448499</td>\n",
       "      <td>5746.677389</td>\n",
       "      <td>215693.562100</td>\n",
       "      <td>725932.8906</td>\n",
       "      <td>0.297126</td>\n",
       "      <td>1107.203543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>6927.863898</td>\n",
       "      <td>0.251434</td>\n",
       "      <td>7435.299512</td>\n",
       "      <td>507.609961</td>\n",
       "      <td>0.496417</td>\n",
       "      <td>-105.486628</td>\n",
       "      <td>0.026887</td>\n",
       "      <td>1.020308</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>23.156102</td>\n",
       "      <td>1045605.237</td>\n",
       "      <td>2.214610e-05</td>\n",
       "      <td>7180.492375</td>\n",
       "      <td>-3.996123</td>\n",
       "      <td>7380.647332</td>\n",
       "      <td>504.388726</td>\n",
       "      <td>-1.213817</td>\n",
       "      <td>-114.297998</td>\n",
       "      <td>0.028224</td>\n",
       "      <td>-2.712267</td>\n",
       "      <td>0.564959</td>\n",
       "      <td>19.473925</td>\n",
       "      <td>172672.97210</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7804.597004</td>\n",
       "      <td>438.284572</td>\n",
       "      <td>-0.340086</td>\n",
       "      <td>-13.597957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.208815</td>\n",
       "      <td>1038.879183</td>\n",
       "      <td>1.660866e+06</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>217.255563</td>\n",
       "      <td>-2.342927</td>\n",
       "      <td>7796.361940</td>\n",
       "      <td>432.800214</td>\n",
       "      <td>3.764069</td>\n",
       "      <td>-19.737818</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.165365</td>\n",
       "      <td>20.012149</td>\n",
       "      <td>480.813517</td>\n",
       "      <td>13220.86100</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>436.462066</td>\n",
       "      <td>-2.330775</td>\n",
       "      <td>7774.980156</td>\n",
       "      <td>428.233753</td>\n",
       "      <td>5.437413</td>\n",
       "      <td>-23.589648</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>-0.078834</td>\n",
       "      <td>13.971929</td>\n",
       "      <td>329.548141</td>\n",
       "      <td>6202.647747</td>\n",
       "      <td>0.053130</td>\n",
       "      <td>647.140794</td>\n",
       "      <td>-2.427941</td>\n",
       "      <td>7763.854380</td>\n",
       "      <td>429.871378</td>\n",
       "      <td>-0.677972</td>\n",
       "      <td>-35.138266</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>-5.282194</td>\n",
       "      <td>6.288061</td>\n",
       "      <td>149.663678</td>\n",
       "      <td>402025.2667</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>856.602837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18373.333540</td>\n",
       "      <td>425.454268</td>\n",
       "      <td>-3.073235</td>\n",
       "      <td>75.937858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.186187</td>\n",
       "      <td>31.389839</td>\n",
       "      <td>1.916524e+04</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>209.276126</td>\n",
       "      <td>0.049345</td>\n",
       "      <td>18411.904950</td>\n",
       "      <td>426.348315</td>\n",
       "      <td>-4.766514</td>\n",
       "      <td>70.967355</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>3.655792</td>\n",
       "      <td>36.092076</td>\n",
       "      <td>8000.68696</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>422.561394</td>\n",
       "      <td>4.484183</td>\n",
       "      <td>18443.589570</td>\n",
       "      <td>420.161214</td>\n",
       "      <td>-2.831612</td>\n",
       "      <td>64.400536</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.559263</td>\n",
       "      <td>4.446993</td>\n",
       "      <td>42.565031</td>\n",
       "      <td>22017.324550</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>636.736335</td>\n",
       "      <td>-2.779579</td>\n",
       "      <td>18481.985120</td>\n",
       "      <td>430.549806</td>\n",
       "      <td>-1.311109</td>\n",
       "      <td>57.976933</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>-1.616969</td>\n",
       "      <td>5.498423</td>\n",
       "      <td>55.148833</td>\n",
       "      <td>107837.4263</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>851.879525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.521291</td>\n",
       "      <td>240.365164</td>\n",
       "      <td>2.128843</td>\n",
       "      <td>203.312840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>1.397698</td>\n",
       "      <td>1.274840e+04</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>157.357468</td>\n",
       "      <td>-4.928751</td>\n",
       "      <td>234.878311</td>\n",
       "      <td>382.303666</td>\n",
       "      <td>2.472147</td>\n",
       "      <td>315.546032</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>-0.806470</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>1.467883</td>\n",
       "      <td>23914.89189</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>379.051363</td>\n",
       "      <td>8.080504</td>\n",
       "      <td>416.285139</td>\n",
       "      <td>535.372143</td>\n",
       "      <td>-5.455871</td>\n",
       "      <td>430.496889</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.271463</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>1.546577</td>\n",
       "      <td>9629.049472</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>684.687115</td>\n",
       "      <td>-0.570831</td>\n",
       "      <td>667.705737</td>\n",
       "      <td>693.951408</td>\n",
       "      <td>1.437519</td>\n",
       "      <td>558.573426</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>-0.276236</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>1.543468</td>\n",
       "      <td>233040.2440</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1071.318394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>11144.453900</td>\n",
       "      <td>-2.396327</td>\n",
       "      <td>8578.926296</td>\n",
       "      <td>655.212169</td>\n",
       "      <td>-0.395016</td>\n",
       "      <td>448.525488</td>\n",
       "      <td>0.025959</td>\n",
       "      <td>-15.357358</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>2.133977</td>\n",
       "      <td>2751277.321</td>\n",
       "      <td>7.756310e-07</td>\n",
       "      <td>11471.083940</td>\n",
       "      <td>-1.158901</td>\n",
       "      <td>8803.146379</td>\n",
       "      <td>643.381730</td>\n",
       "      <td>2.630166</td>\n",
       "      <td>430.992668</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>-0.167525</td>\n",
       "      <td>0.047391</td>\n",
       "      <td>2.228423</td>\n",
       "      <td>59837.19256</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11786.42253</td>\n",
       "      <td>-2.079459</td>\n",
       "      <td>9014.977204</td>\n",
       "      <td>628.852352</td>\n",
       "      <td>-1.793284</td>\n",
       "      <td>421.374077</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>-0.646625</td>\n",
       "      <td>0.050773</td>\n",
       "      <td>2.227213</td>\n",
       "      <td>122969.9981</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  posX_0  posY_0        posZ_0      velX_0    velY_0      velZ_0  \\\n",
       "0           0       0       0    476.575674  486.926974  3.057090  305.119216   \n",
       "1           1       0       0   8073.292719  561.240579  0.939582   16.840572   \n",
       "2           2       0       0   7804.597004  438.284572 -0.340086  -13.597957   \n",
       "3           3       0       0  18373.333540  425.454268 -3.073235   75.937858   \n",
       "4           4       0       0     98.521291  240.365164  2.128843  203.312840   \n",
       "\n",
       "   diffposX_0  diffposX_0.1  diffposX_0.2  diffposX_0.3  diffposX_0.4  \\\n",
       "0           0             0      0.005119      2.546763  2.536945e+04   \n",
       "1           0             0     28.466693   1110.668463  3.568034e+05   \n",
       "2           0             0     42.208815   1038.879183  1.660866e+06   \n",
       "3           0             0      3.186187     31.389839  1.916524e+04   \n",
       "4           0             0      0.002383      1.397698  1.274840e+04   \n",
       "\n",
       "   diffposX_0.5      posX_1    posY_1        posZ_1      velX_1    velY_1  \\\n",
       "0      0.000100  241.974495 -3.247714    629.299199  483.225599 -0.534244   \n",
       "1      0.003113  284.446308  1.729876   8071.527369  555.568670  0.692598   \n",
       "2      0.000626  217.255563 -2.342927   7796.361940  432.800214  3.764069   \n",
       "3      0.001638  209.276126  0.049345  18411.904950  426.348315 -4.766514   \n",
       "4      0.000110  157.357468 -4.928751    234.878311  382.303666  2.472147   \n",
       "\n",
       "       velZ_1  diffposX_1  diffposX_1.1  diffposX_1.2  diffposX_1.3  \\\n",
       "0  305.483552    0.001036    -11.378862      0.006743      2.502213   \n",
       "1    3.101450    0.000922      3.606218    839.124113  32088.245410   \n",
       "2  -19.737818    0.001160     -0.165365     20.012149    480.813517   \n",
       "3   70.967355    0.001151      0.002172      3.655792     36.092076   \n",
       "4  315.546032    0.001077     -0.806470      0.002359      1.467883   \n",
       "\n",
       "   diffposX_1.4  diffposX_1.5      posX_2    posY_2        posZ_2      velX_2  \\\n",
       "0  818127.34580      0.000003  478.641960  2.505416    775.303988  479.884574   \n",
       "1  643446.46760      0.049869  554.676870 -4.008367   8074.335689  555.637391   \n",
       "2   13220.86100      0.036368  436.462066 -2.330775   7774.980156  428.233753   \n",
       "3    8000.68696      0.004511  422.561394  4.484183  18443.589570  420.161214   \n",
       "4   23914.89189      0.000061  379.051363  8.080504    416.285139  535.372143   \n",
       "\n",
       "     velY_2      velZ_2  diffposX_2  diffposX_2.1  diffposX_2.2  diffposX_2.3  \\\n",
       "0  2.569264  295.705799    0.002078      0.379544      0.008867      2.633625   \n",
       "1 -2.662952    5.754135    0.001797     -0.565250    243.863485   9324.443030   \n",
       "2  5.437413  -23.589648    0.002380     -0.078834     13.971929    329.548141   \n",
       "3 -2.831612   64.400536    0.002394      0.559263      4.446993     42.565031   \n",
       "4 -5.455871  430.496889    0.001322      0.271463      0.002246      1.546577   \n",
       "\n",
       "   diffposX_2.4  diffposX_2.5      posX_3    posY_3        posZ_3      velX_3  \\\n",
       "0  34886.387910      0.000075  722.250011  1.029778    918.981911  476.162385   \n",
       "1  43536.770180      0.214174  834.907832  3.528096   8076.754846  550.590398   \n",
       "2   6202.647747      0.053130  647.140794 -2.427941   7763.854380  429.871378   \n",
       "3  22017.324550      0.001933  636.736335 -2.779579  18481.985120  430.549806   \n",
       "4   9629.049472      0.000161  684.687115 -0.570831    667.705737  693.951408   \n",
       "\n",
       "     velY_3      velZ_3  diffposX_3  diffposX_3.1  diffposX_3.2  \\\n",
       "0 -0.844225  284.568090    0.003185      1.444865      0.011348   \n",
       "1  0.646220   -1.185523    0.002754      8.448499   5746.677389   \n",
       "2 -0.677972  -35.138266    0.003502     -5.282194      6.288061   \n",
       "3 -1.311109   57.976933    0.003435     -1.616969      5.498423   \n",
       "4  1.437519  558.573426    0.001422     -0.276236      0.002140   \n",
       "\n",
       "    diffposX_3.3  diffposX_3.4  diffposX_3.5       posX_4  ...    \\\n",
       "0       2.799869   318121.9958      0.000009   958.719915  ...     \n",
       "1  215693.562100   725932.8906      0.297126  1107.203543  ...     \n",
       "2     149.663678   402025.2667      0.000372   856.602837  ...     \n",
       "3      55.148833   107837.4263      0.000511   851.879525  ...     \n",
       "4       1.543468   233040.2440      0.000007  1071.318394  ...     \n",
       "\n",
       "   diffposX_25.5       posX_26   posY_26      posZ_26     velX_26   velY_26  \\\n",
       "0       0.000000      0.000000  0.000000     0.000000    0.000000  0.000000   \n",
       "1       0.000033   6927.863898  0.251434  7435.299512  507.609961  0.496417   \n",
       "2       0.000000      0.000000  0.000000     0.000000    0.000000  0.000000   \n",
       "3       0.000000      0.000000  0.000000     0.000000    0.000000  0.000000   \n",
       "4       0.000033  11144.453900 -2.396327  8578.926296  655.212169 -0.395016   \n",
       "\n",
       "      velZ_26  diffposX_26  diffposX_26.1  diffposX_26.2  diffposX_26.3  \\\n",
       "0    0.000000     0.000000       0.000000       0.000000       0.000000   \n",
       "1 -105.486628     0.026887       1.020308       0.668196      23.156102   \n",
       "2    0.000000     0.000000       0.000000       0.000000       0.000000   \n",
       "3    0.000000     0.000000       0.000000       0.000000       0.000000   \n",
       "4  448.525488     0.025959     -15.357358       0.042644       2.133977   \n",
       "\n",
       "   diffposX_26.4  diffposX_26.5       posX_27   posY_27      posZ_27  \\\n",
       "0          0.000   0.000000e+00      0.000000  0.000000     0.000000   \n",
       "1    1045605.237   2.214610e-05   7180.492375 -3.996123  7380.647332   \n",
       "2          0.000   0.000000e+00      0.000000  0.000000     0.000000   \n",
       "3          0.000   0.000000e+00      0.000000  0.000000     0.000000   \n",
       "4    2751277.321   7.756310e-07  11471.083940 -1.158901  8803.146379   \n",
       "\n",
       "      velX_27   velY_27     velZ_27  diffposX_27  diffposX_27.1  \\\n",
       "0    0.000000  0.000000    0.000000     0.000000       0.000000   \n",
       "1  504.388726 -1.213817 -114.297998     0.028224      -2.712267   \n",
       "2    0.000000  0.000000    0.000000     0.000000       0.000000   \n",
       "3    0.000000  0.000000    0.000000     0.000000       0.000000   \n",
       "4  643.381730  2.630166  430.992668     0.027712      -0.167525   \n",
       "\n",
       "   diffposX_27.2  diffposX_27.3  diffposX_27.4  diffposX_27.5      posX_28  \\\n",
       "0       0.000000       0.000000        0.00000       0.000000      0.00000   \n",
       "1       0.564959      19.473925   172672.97210       0.000113      0.00000   \n",
       "2       0.000000       0.000000        0.00000       0.000000      0.00000   \n",
       "3       0.000000       0.000000        0.00000       0.000000      0.00000   \n",
       "4       0.047391       2.228423    59837.19256       0.000037  11786.42253   \n",
       "\n",
       "    posY_28      posZ_28     velX_28   velY_28     velZ_28  diffposX_28  \\\n",
       "0  0.000000     0.000000    0.000000  0.000000    0.000000     0.000000   \n",
       "1  0.000000     0.000000    0.000000  0.000000    0.000000     0.000000   \n",
       "2  0.000000     0.000000    0.000000  0.000000    0.000000     0.000000   \n",
       "3  0.000000     0.000000    0.000000  0.000000    0.000000     0.000000   \n",
       "4 -2.079459  9014.977204  628.852352 -1.793284  421.374077     0.029805   \n",
       "\n",
       "   diffposX_28.1  diffposX_28.2  diffposX_28.3  diffposX_28.4  diffposX_28.5  \\\n",
       "0       0.000000       0.000000       0.000000         0.0000       0.000000   \n",
       "1       0.000000       0.000000       0.000000         0.0000       0.000000   \n",
       "2       0.000000       0.000000       0.000000         0.0000       0.000000   \n",
       "3       0.000000       0.000000       0.000000         0.0000       0.000000   \n",
       "4      -0.646625       0.050773       2.227213    122969.9981       0.000018   \n",
       "\n",
       "   posX_29  posY_29  posZ_29  velX_29  velY_29  velZ_29  diffposX_29  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0          0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0          0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0          0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0          0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0          0.0   \n",
       "\n",
       "   diffposX_29.1  diffposX_29.2  diffposX_29.3  diffposX_29.4  diffposX_29.5  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   class  \n",
       "0      3  \n",
       "1     14  \n",
       "2     21  \n",
       "3     14  \n",
       "4     20  \n",
       "\n",
       "[5 rows x 362 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qq = list(range(1,361))\n",
    "X = train_data.iloc[:,qq].as_matrix()\n",
    "y = train_data.iloc[:,-1].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler = scaler.fit(X)\n",
    "# normalize the dataset and print\n",
    "normalized = scaler.transform(X)\n",
    "# inverse transform and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28746, 360)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = normalized.reshape(28746,30,12)\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_new, dummy_y, test_size=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27308, 30, 12)\n",
      "(1438, 30, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y,columns=[['y']])\n",
    "df = pd.DataFrame(df.groupby(['y'])['y'].count())\n",
    "df['freq'] = round((df['y']/df['y'].sum()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = df.index -1 \n",
    "weight = df.freq.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None ,X_train.shape[2]),return_sequences=True,activation='sigmoid',recurrent_activation='tanh'))\n",
    "model.add(LSTM(256, return_sequences=False,activation='sigmoid',recurrent_activation='tanh'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))#Create output layer\n",
    "\n",
    "# Compile model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27308 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0227 - acc: 0.7567 - val_loss: 0.7323 - val_acc: 0.6815\n",
      "Epoch 2/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0216 - acc: 0.7703 - val_loss: 0.7557 - val_acc: 0.6808\n",
      "Epoch 3/20\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0207 - acc: 0.7804 - val_loss: 0.7233 - val_acc: 0.6829\n",
      "Epoch 4/20\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0206 - acc: 0.7812 - val_loss: 0.7240 - val_acc: 0.6773\n",
      "Epoch 5/20\n",
      "27308/27308 [==============================] - 37s 1ms/step - loss: 0.0201 - acc: 0.7882 - val_loss: 0.7201 - val_acc: 0.6829\n",
      "Epoch 6/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0199 - acc: 0.7891 - val_loss: 0.7249 - val_acc: 0.6843\n",
      "Epoch 7/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0197 - acc: 0.7913 - val_loss: 0.7237 - val_acc: 0.6843\n",
      "Epoch 8/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0197 - acc: 0.7916 - val_loss: 0.7276 - val_acc: 0.6829\n",
      "Epoch 9/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0196 - acc: 0.7931 - val_loss: 0.7296 - val_acc: 0.6850\n",
      "Epoch 10/20\n",
      "27308/27308 [==============================] - 37s 1ms/step - loss: 0.0196 - acc: 0.7935 - val_loss: 0.7309 - val_acc: 0.6801\n",
      "Epoch 11/20\n",
      "27308/27308 [==============================] - 36s 1ms/step - loss: 0.0195 - acc: 0.7936 - val_loss: 0.7302 - val_acc: 0.6864\n",
      "Epoch 12/20\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0195 - acc: 0.7945 - val_loss: 0.7302 - val_acc: 0.6871\n",
      "Epoch 13/20\n",
      "27308/27308 [==============================] - 39s 1ms/step - loss: 0.0194 - acc: 0.7953 - val_loss: 0.7287 - val_acc: 0.6836\n",
      "Epoch 14/20\n",
      "27308/27308 [==============================] - 40s 1ms/step - loss: 0.0194 - acc: 0.7955 - val_loss: 0.7286 - val_acc: 0.6843\n",
      "Epoch 15/20\n",
      "27308/27308 [==============================] - 39s 1ms/step - loss: 0.0194 - acc: 0.7954 - val_loss: 0.7298 - val_acc: 0.6829\n",
      "Epoch 16/20\n",
      "27308/27308 [==============================] - 39s 1ms/step - loss: 0.0194 - acc: 0.7969 - val_loss: 0.7332 - val_acc: 0.6787\n",
      "Epoch 17/20\n",
      "27308/27308 [==============================] - 40s 1ms/step - loss: 0.0195 - acc: 0.7960 - val_loss: 0.7396 - val_acc: 0.6829\n",
      "Epoch 18/20\n",
      "27308/27308 [==============================] - 40s 1ms/step - loss: 0.0197 - acc: 0.7920 - val_loss: 0.7561 - val_acc: 0.6822\n",
      "Epoch 19/20\n",
      "27308/27308 [==============================] - 42s 2ms/step - loss: 0.0200 - acc: 0.7880 - val_loss: 0.7791 - val_acc: 0.6690\n",
      "Epoch 20/20\n",
      "27308/27308 [==============================] - 40s 1ms/step - loss: 0.0204 - acc: 0.7819 - val_loss: 0.7737 - val_acc: 0.6697\n",
      "Wall time: 12min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 50\n",
    "batch_size = [256,512,1024,2048,4096]\n",
    "\n",
    "# fit network\n",
    "for i in batch_size:\n",
    "    trained = model.fit(X_train, y_train, epochs=epochs, batch_size=i, \n",
    "                        validation_data=(X_val, y_val), verbose=1, shuffle=False,class_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27308 samples, validate on 1438 samples\n",
      "Epoch 1/10\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0215 - acc: 0.7730 - val_loss: 0.7526 - val_acc: 0.6739\n",
      "Epoch 2/10\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0205 - acc: 0.7845 - val_loss: 0.7447 - val_acc: 0.6620\n",
      "Epoch 3/10\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0197 - acc: 0.7943 - val_loss: 0.7416 - val_acc: 0.6718\n",
      "Epoch 4/10\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0193 - acc: 0.8007 - val_loss: 0.7360 - val_acc: 0.6773\n",
      "Epoch 5/10\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0189 - acc: 0.8044 - val_loss: 0.7336 - val_acc: 0.6766\n",
      "Epoch 6/10\n",
      "27308/27308 [==============================] - 38s 1ms/step - loss: 0.0185 - acc: 0.8067 - val_loss: 0.7327 - val_acc: 0.6794\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-22be2598a3a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras-2.0.9-py3.6.egg\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras-2.0.9-py3.6.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras-2.0.9-py3.6.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras-2.0.9-py3.6.egg\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = model\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=4096,validation_data=(X_val, y_val), verbose=1, shuffle=False,class_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_proba = model.predict_proba(X_val)\n",
    "pred_ = model.predict_classes(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_val.argmax(axis=1), pred_)\n",
    "plt.figure()\n",
    "classes = range(0,25)\n",
    "plot_confusion_matrix(cnf_matrix, classes, normalize=True, doprint=False, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=pred_,y_true=y_val.argmax(axis=1)))\n",
    "print('log_loss: {}'.format(log_loss(y_pred=pred_proba,y_true=y_val.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + name + 'test_new.csv')\n",
    "test_dataX = test_data.iloc[:,qq].as_matrix()\n",
    "normalized_test = scaler.transform(test_dataX)\n",
    "normalized_test = normalized_test.reshape(271251,30,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = new_model.predict_classes(normalized_test)\n",
    "pred = pred.astype(int)\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv(out_name, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compress result file\n",
    "import gzip\n",
    "\n",
    "in_data = open(out_name, \"rb\").read()\n",
    "out_gz = out_name+\".gz\"\n",
    "gzf = gzip.open(out_gz, \"wb\")\n",
    "gzf.write(in_data)\n",
    "gzf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_name, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_data = open(out_name, \"rb\").read()\n",
    "out_gz = out_name+\".gz\"\n",
    "gzf = gzip.open(out_gz, \"wb\")\n",
    "gzf.write(in_data)\n",
    "gzf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
